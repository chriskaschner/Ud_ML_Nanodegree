{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = 'weights/vgg16_weights.h5'\n",
    "top_model_weights_path = 'fc_model.h5'\n",
    "train_data_dir = 'data2/train/attempt1'\n",
    "validation_data_dir = 'data2/validation/attempt1'\n",
    "nb_train_samples = 870\n",
    "nb_validation_samples = 260\n",
    "nb_epoch = 10\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(3,img_width, img_height)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "def plot(model, to_file='model.png'):                                           \n",
    "\n",
    "    graph = pydot.Dot(graph_type='digraph')                                     \n",
    "    if type(model) == Sequential:                                                                                                              \n",
    "        previous_node = None                                                                                                                   \n",
    "        written_nodes = []                                                      \n",
    "        n = 1                                                                                                                                  \n",
    "        for layer in model.layers:                                              \n",
    "            # append number in case layers have same name to differentiate      \n",
    "            config = layer.get_config()                                         \n",
    "            if (config['name'] + str(n)) in written_nodes:                      \n",
    "                n += 1                                                          \n",
    "            current_node = pydot.Node(config['name'] + str(n))                  \n",
    "            written_nodes.append(config['name'] + str(n))                       \n",
    "            graph.add_node(current_node)                                            \n",
    "            if previous_node:                                                   \n",
    "                graph.add_edge(pydot.Edge(previous_node, current_node))             \n",
    "            previous_node = current_node                                                \n",
    "        graph.write_png(to_file)                                                    \n",
    "\n",
    "    elif type(model) == Graph:                                                      \n",
    "        config = model.get_config()                                                 \n",
    "        # don't need to append number for names since all nodes labeled                 \n",
    "        for input_node in config['input_config']:                                   \n",
    "            graph.add_node(pydot.Node(input_node['name']))                      \n",
    "\n",
    "        # intermediate and output nodes have input defined                      \n",
    "        for layer_config in [config['node_config'], config['output_config']]:   \n",
    "            for node in layer_config:                                           \n",
    "                graph.add_node(pydot.Node(node['name']))                        \n",
    "                # possible to have multiple 'inputs' vs 1 'input'               \n",
    "                if node['inputs']:                                              \n",
    "                    for e in node['inputs']:                                    \n",
    "                        graph.add_edge(pydot.Edge(e, node['name']))             \n",
    "                else:                                                           \n",
    "                    graph.add_edge(pydot.Edge(node['input'], node['name']))     \n",
    "\n",
    "        graph.write_png(to_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers.pop()\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = preprocess_image_batch(['data2/nike-1.jpg'],img_size=(256,256), crop_size=(img_width, img_height), color_mode=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize, imsave\n",
    "im = preprocess_image_batch(['data2/nike-1.jpg','data2/nike-2.jpg','data2/nike-3.jpg','data2/nike-4.jpg','data2/nike-5.jpg','data2/nike-6.jpg'],img_size=(256,256), crop_size=(img_width, img_height), color_mode=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(im)\n",
    "print np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top 5 predictions\n",
    "np.argsort(out)[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize, imsave\n",
    "\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode=\"rgb\", out=None):\n",
    "    img_list = []\n",
    "    \n",
    "    for im_path in image_paths:\n",
    "        img = imread(im_path, mode='RGB')\n",
    "        if img_size:\n",
    "            img = imresize(img,img_size)\n",
    "            \n",
    "        img = img.astype('float32')\n",
    "        # We permute the colors to get them in the BGR order\n",
    "        if color_mode==\"bgr\":\n",
    "            img[:,:,[0,1,2]] = img[:,:,[2,1,0]]\n",
    "        # We normalize the colors with the empirical means on the training set\n",
    "        img[:, :, 0] -= 123.68 \n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 103.939\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        if crop_size:\n",
    "            img = img[:,(img_size[0]-crop_size[0])//2:(img_size[0]+crop_size[0])//2\n",
    "                      ,(img_size[1]-crop_size[1])//2:(img_size[1]+crop_size[1])//2]\n",
    "            \n",
    "        img_list.append(img)\n",
    "\n",
    "    img_batch = np.stack(img_list, axis=0)\n",
    "    if not out is None:\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
