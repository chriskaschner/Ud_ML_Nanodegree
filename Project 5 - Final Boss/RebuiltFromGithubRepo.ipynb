{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = 'weights/vgg16_weights.h5'\n",
    "top_model_weights_path = 'fc_model.h5'\n",
    "train_data_dir = 'data2/train/attempt1'\n",
    "validation_data_dir = 'data2/validation/attempt1'\n",
    "validation_pre_image = 'data2/train/preimage'\n",
    "train_pre_image = 'data2/train/preimage'\n",
    "log_path = 'logs'\n",
    "nb_train_samples = 870\n",
    "nb_validation_samples = 260\n",
    "nb_epoch = 10\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(3,img_width, img_height)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000)\n",
      "<keras.layers.core.Dense object at 0x11c246a10>\n"
     ]
    }
   ],
   "source": [
    "print model.output_shape\n",
    "print model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x11c246a10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000)\n",
      "<keras.layers.core.Dropout object at 0x11c246ed0>\n"
     ]
    }
   ],
   "source": [
    "print model.output_shape\n",
    "print model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dropout at 0x11c246ed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000)\n",
      "<keras.layers.core.Dense object at 0x11c217a90>\n"
     ]
    }
   ],
   "source": [
    "print model.output_shape\n",
    "print model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "def plot(model, to_file='model.png'):                                           \n",
    "\n",
    "    graph = pydot.Dot(graph_type='digraph')                                     \n",
    "    if type(model) == Sequential:                                                                                                              \n",
    "        previous_node = None                                                                                                                   \n",
    "        written_nodes = []                                                      \n",
    "        n = 1                                                                                                                                  \n",
    "        for layer in model.layers:                                              \n",
    "            # append number in case layers have same name to differentiate      \n",
    "            config = layer.get_config()                                         \n",
    "            if (config['name'] + str(n)) in written_nodes:                      \n",
    "                n += 1                                                          \n",
    "            current_node = pydot.Node(config['name'] + str(n))                  \n",
    "            written_nodes.append(config['name'] + str(n))                       \n",
    "            graph.add_node(current_node)                                            \n",
    "            if previous_node:                                                   \n",
    "                graph.add_edge(pydot.Edge(previous_node, current_node))             \n",
    "            previous_node = current_node                                                \n",
    "        graph.write_png(to_file)                                                    \n",
    "\n",
    "    elif type(model) == Graph:                                                      \n",
    "        config = model.get_config()                                                 \n",
    "        # don't need to append number for names since all nodes labeled                 \n",
    "        for input_node in config['input_config']:                                   \n",
    "            graph.add_node(pydot.Node(input_node['name']))                      \n",
    "\n",
    "        # intermediate and output nodes have input defined                      \n",
    "        for layer_config in [config['node_config'], config['output_config']]:   \n",
    "            for node in layer_config:                                           \n",
    "                graph.add_node(pydot.Node(node['name']))                        \n",
    "                # possible to have multiple 'inputs' vs 1 'input'               \n",
    "                if node['inputs']:                                              \n",
    "                    for e in node['inputs']:                                    \n",
    "                        graph.add_edge(pydot.Edge(e, node['name']))             \n",
    "                else:                                                           \n",
    "                    graph.add_edge(pydot.Edge(node['input'], node['name']))     \n",
    "\n",
    "        graph.write_png(to_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x11b17ba10>\n",
      "(None, 3)\n"
     ]
    }
   ],
   "source": [
    "print model.layers[-1]\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir='logs', histogram_freq=1, write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = preprocess_image_batch(['data2/nike-5.jpg'],img_size=(256,256), crop_size=(img_width, img_height), color_mode=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize, imsave\n",
    "im = preprocess_image_batch(['data2/nike-1.jpg','data2/nike-2.jpg','data2/nike-3.jpg','data2/nike-4.jpg','data2/nike-5.jpg','data2/nike-6.jpg'],img_size=(256,256), crop_size=(img_width, img_height), color_mode=\"bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(im)\n",
    "print np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11596757  0.55395323  0.3300792 ]]\n"
     ]
    }
   ],
   "source": [
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 1],\n",
       "       [0, 2, 1],\n",
       "       [0, 2, 1],\n",
       "       [0, 2, 1],\n",
       "       [0, 2, 1],\n",
       "       [0, 2, 1]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top 5 predictions\n",
    "np.argsort(out)[::-1][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 870 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        save_to_dir=train_pre_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=3,\n",
    "        class_mode='binary',\n",
    "        save_to_dir=validation_pre_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class mode binary above, is that correct?\n",
    "# switching it to 'categorical' breaks the fine-tuning below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "870/870 [==============================] - 1289s - loss: 0.9838 - val_loss: 0.7183\n",
      "Epoch 2/10\n",
      "870/870 [==============================] - 1270s - loss: 0.9580 - val_loss: 0.7331\n",
      "Epoch 3/10\n",
      "870/870 [==============================] - 1266s - loss: 0.9579 - val_loss: 0.8343\n",
      "Epoch 4/10\n",
      "870/870 [==============================] - 1262s - loss: 0.9559 - val_loss: 0.7954\n",
      "Epoch 5/10\n",
      "870/870 [==============================] - 1265s - loss: 0.9545 - val_loss: 0.7178\n",
      "Epoch 6/10\n",
      "870/870 [==============================] - 1264s - loss: 0.9609 - val_loss: 0.7634\n",
      "Epoch 7/10\n",
      "870/870 [==============================] - 1263s - loss: 0.9520 - val_loss: 0.7724\n",
      "Epoch 8/10\n",
      "870/870 [==============================] - 1263s - loss: 0.9554 - val_loss: 0.8083\n",
      "Epoch 9/10\n",
      "870/870 [==============================] - 1262s - loss: 0.9614 - val_loss: 0.7649\n",
      "Epoch 10/10\n",
      "870/870 [==============================] - 1262s - loss: 0.9555 - val_loss: 0.7464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x150f2f490>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize, imsave\n",
    "\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode=\"rgb\", out=None):\n",
    "    img_list = []\n",
    "    \n",
    "    for im_path in image_paths:\n",
    "        img = imread(im_path, mode='RGB')\n",
    "        if img_size:\n",
    "            img = imresize(img,img_size)\n",
    "            \n",
    "        img = img.astype('float32')\n",
    "        # We permute the colors to get them in the BGR order\n",
    "        if color_mode==\"bgr\":\n",
    "            img[:,:,[0,1,2]] = img[:,:,[2,1,0]]\n",
    "        # We normalize the colors with the empirical means on the training set\n",
    "        img[:, :, 0] -= 123.68 \n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 103.939\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        if crop_size:\n",
    "            img = img[:,(img_size[0]-crop_size[0])//2:(img_size[0]+crop_size[0])//2\n",
    "                      ,(img_size[1]-crop_size[1])//2:(img_size[1]+crop_size[1])//2]\n",
    "            \n",
    "        img_list.append(img)\n",
    "\n",
    "    img_batch = np.stack(img_list, axis=0)\n",
    "    if not out is None:\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
